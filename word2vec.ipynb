{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "066bc8fb",
   "metadata": {},
   "source": [
    "# –ò–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b24ed42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dostoevsky\n",
      "  Downloading dostoevsky-0.6.0-py2.py3-none-any.whl (8.5 kB)\n",
      "Collecting fasttext==0.9.2\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "Collecting razdel==0.5.0\n",
      "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
      "Collecting pybind11>=2.2\n",
      "  Using cached pybind11-2.10.4-py3-none-any.whl (222 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from fasttext==0.9.2->dostoevsky) (52.0.0.post20210125)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from fasttext==0.9.2->dostoevsky) (1.24.2)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py): started\n",
      "  Building wheel for fasttext (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for fasttext\n",
      "Failed to build fasttext\n",
      "Installing collected packages: pybind11, razdel, fasttext, dostoevsky\n",
      "    Running setup.py install for fasttext: started\n",
      "    Running setup.py install for fasttext: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\ProgramData\\Anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Temp\\\\pip-install-wcyfwoft\\\\fasttext_0c109378270f49c39b4a1717b03af06e\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Temp\\\\pip-install-wcyfwoft\\\\fasttext_0c109378270f49c39b4a1717b03af06e\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Temp\\pip-wheel-nxicduxs'\n",
      "       cwd: C:\\Temp\\pip-install-wcyfwoft\\fasttext_0c109378270f49c39b4a1717b03af06e\\\n",
      "  Complete output (18 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.8\n",
      "  creating build\\lib.win-amd64-3.8\\fasttext\n",
      "  copying python\\fasttext_module\\fasttext\\FastText.py -> build\\lib.win-amd64-3.8\\fasttext\n",
      "  copying python\\fasttext_module\\fasttext\\__init__.py -> build\\lib.win-amd64-3.8\\fasttext\n",
      "  creating build\\lib.win-amd64-3.8\\fasttext\\util\n",
      "  copying python\\fasttext_module\\fasttext\\util\\util.py -> build\\lib.win-amd64-3.8\\fasttext\\util\n",
      "  copying python\\fasttext_module\\fasttext\\util\\__init__.py -> build\\lib.win-amd64-3.8\\fasttext\\util\n",
      "  creating build\\lib.win-amd64-3.8\\fasttext\\tests\n",
      "  copying python\\fasttext_module\\fasttext\\tests\\test_configurations.py -> build\\lib.win-amd64-3.8\\fasttext\\tests\n",
      "  copying python\\fasttext_module\\fasttext\\tests\\test_script.py -> build\\lib.win-amd64-3.8\\fasttext\\tests\n",
      "  copying python\\fasttext_module\\fasttext\\tests\\__init__.py -> build\\lib.win-amd64-3.8\\fasttext\\tests\n",
      "  running build_ext\n",
      "  building 'fasttext_pybind' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for fasttext\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\ProgramData\\Anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Temp\\\\pip-install-wcyfwoft\\\\fasttext_0c109378270f49c39b4a1717b03af06e\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Temp\\\\pip-install-wcyfwoft\\\\fasttext_0c109378270f49c39b4a1717b03af06e\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Temp\\pip-record-06lwa84s\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\ProgramData\\Anaconda3\\Include\\fasttext'\n",
      "         cwd: C:\\Temp\\pip-install-wcyfwoft\\fasttext_0c109378270f49c39b4a1717b03af06e\\\n",
      "    Complete output (18 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.8\n",
      "    creating build\\lib.win-amd64-3.8\\fasttext\n",
      "    copying python\\fasttext_module\\fasttext\\FastText.py -> build\\lib.win-amd64-3.8\\fasttext\n",
      "    copying python\\fasttext_module\\fasttext\\__init__.py -> build\\lib.win-amd64-3.8\\fasttext\n",
      "    creating build\\lib.win-amd64-3.8\\fasttext\\util\n",
      "    copying python\\fasttext_module\\fasttext\\util\\util.py -> build\\lib.win-amd64-3.8\\fasttext\\util\n",
      "    copying python\\fasttext_module\\fasttext\\util\\__init__.py -> build\\lib.win-amd64-3.8\\fasttext\\util\n",
      "    creating build\\lib.win-amd64-3.8\\fasttext\\tests\n",
      "    copying python\\fasttext_module\\fasttext\\tests\\test_configurations.py -> build\\lib.win-amd64-3.8\\fasttext\\tests\n",
      "    copying python\\fasttext_module\\fasttext\\tests\\test_script.py -> build\\lib.win-amd64-3.8\\fasttext\\tests\n",
      "    copying python\\fasttext_module\\fasttext\\tests\\__init__.py -> build\\lib.win-amd64-3.8\\fasttext\\tests\n",
      "    running build_ext\n",
      "    building 'fasttext_pybind' extension\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\ProgramData\\Anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Temp\\\\pip-install-wcyfwoft\\\\fasttext_0c109378270f49c39b4a1717b03af06e\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Temp\\\\pip-install-wcyfwoft\\\\fasttext_0c109378270f49c39b4a1717b03af06e\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Temp\\pip-record-06lwa84s\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\ProgramData\\Anaconda3\\Include\\fasttext' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "!pip install dostoevsky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f774f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from gensim.models import Word2Vec as wv\n",
    "from gensim.models import KeyedVectors\n",
    "import pymorphy2\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import emoji\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d9a517e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\–ú–∞–∫—Å–∏–º\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636dff34",
   "metadata": {},
   "source": [
    "# –î–∞—Ç–∞—Å–µ—Ç –í–ö"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7b111f",
   "metadata": {},
   "source": [
    "## –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6931eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['comment',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c0d93e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('datasets/vk.csv', names=colnames, header=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3155346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['–Ω–æ—Ä–º–∞']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['üòÅ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['–≤–æ—Ä–æ–Ω–∫–∞', '—Ü–≤–µ—Ç–æ–∫', '–≤–æ–¥–∞', 'üíÆ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['—Å—à–∞', '—Ñ–∞—à–∏–∑–º']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['–∑–ª–æ–¥–µ–π', '—Ü–µ–ª—ã–π', '–º–µ—Å—è—Ü', '–∂–¥–∞—Ç—å']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20575</th>\n",
       "      <td>['—Å', '—Ñ–∞–º–∏–ª–∏—è', 'üôÑ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20576</th>\n",
       "      <td>['–Ω–∞—à', '–¥–µ–Ω—å', '–ø–æ–≤–µ–∑—Ç–∏', '–º—É–∂–∏–∫', '—Ñ–∞–º–∏–ª–∏—è',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20577</th>\n",
       "      <td>['—á—É–¥–æ', '—á—É–¥–Ω–æ–π', '–¥–∏–≤–æ', '–¥–∏–≤–Ω—ã–π']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20578</th>\n",
       "      <td>['–ø—Ä–∏–≥—Ä–µ—Ç—å—Å—è', '—É—Å–Ω—É—Ç—å', '—Å–≤–∞—Ä–∏—Ç—å—Å—è', '–ª—è–≥—É—à–∫–∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20579</th>\n",
       "      <td>['–¥–æ–±—Ä—ã–π', '–¥–µ–Ω—å', '–≤–ø–æ–ª–Ω–µ', '–≤–æ–∑–º–æ–∂–Ω–æ', '–ø–µ—Ä–µ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20580 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment\n",
       "0                                              ['–Ω–æ—Ä–º–∞']\n",
       "1                                                  ['üòÅ']\n",
       "2                     ['–≤–æ—Ä–æ–Ω–∫–∞', '—Ü–≤–µ—Ç–æ–∫', '–≤–æ–¥–∞', 'üíÆ']\n",
       "3                                      ['—Å—à–∞', '—Ñ–∞—à–∏–∑–º']\n",
       "4                  ['–∑–ª–æ–¥–µ–π', '—Ü–µ–ª—ã–π', '–º–µ—Å—è—Ü', '–∂–¥–∞—Ç—å']\n",
       "...                                                  ...\n",
       "20575                              ['—Å', '—Ñ–∞–º–∏–ª–∏—è', 'üôÑ']\n",
       "20576  ['–Ω–∞—à', '–¥–µ–Ω—å', '–ø–æ–≤–µ–∑—Ç–∏', '–º—É–∂–∏–∫', '—Ñ–∞–º–∏–ª–∏—è',...\n",
       "20577               ['—á—É–¥–æ', '—á—É–¥–Ω–æ–π', '–¥–∏–≤–æ', '–¥–∏–≤–Ω—ã–π']\n",
       "20578  ['–ø—Ä–∏–≥—Ä–µ—Ç—å—Å—è', '—É—Å–Ω—É—Ç—å', '—Å–≤–∞—Ä–∏—Ç—å—Å—è', '–ª—è–≥—É—à–∫–∞...\n",
       "20579  ['–¥–æ–±—Ä—ã–π', '–¥–µ–Ω—å', '–≤–ø–æ–ª–Ω–µ', '–≤–æ–∑–º–æ–∂–Ω–æ', '–ø–µ—Ä–µ...\n",
       "\n",
       "[20580 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46de53f2",
   "metadata": {},
   "source": [
    "## –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∫ —Ñ–æ—Ä–º–∞—Ç—É —Å–ø–∏—Å–∫–∞ —Å–ø–∏—Å–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49e256ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_list(i):\n",
    "    new_list = eval(i)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "028d67eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_str = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fe2dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_str['comment'] = comments['comment'].apply(str_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd58aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "vk_data = comments['comment'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9971e4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['–Ω–æ—Ä–º–∞']\",\n",
       " \"['üòÅ']\",\n",
       " \"['–≤–æ—Ä–æ–Ω–∫–∞', '—Ü–≤–µ—Ç–æ–∫', '–≤–æ–¥–∞', 'üíÆ']\",\n",
       " \"['—Å—à–∞', '—Ñ–∞—à–∏–∑–º']\",\n",
       " \"['–∑–ª–æ–¥–µ–π', '—Ü–µ–ª—ã–π', '–º–µ—Å—è—Ü', '–∂–¥–∞—Ç—å']\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vk_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff62764",
   "metadata": {},
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏  *(–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ)* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26a64e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = ['üò°', 'üëø', 'üòæ', 'üò§', 'üò†', 'ü§¨', 'üíÄ', '‚ò†Ô∏è']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40a37afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarcastic = ['üí©', 'ü§°', 'üôÉ', 'ü§¢', 'üòà']  # –ù—É–∂–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79c1c4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = ['üòÄ', 'üòÉ', 'üòâ']  # –ù—É–∂–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39386dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
